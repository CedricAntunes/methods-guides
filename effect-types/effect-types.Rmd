---
Author: NA
Title: 10 Types of Treatment Effect You Should Know About
output: html_document
---


Abstract
==
This guide [^1] for more formal discussion of independence and the assumptions necessary to estimate causal effects. describes ten distinct types of causal effect researchers can be interested in estimating. As discussed in our guide to causal inference, simple randomization allows one to produce estimates of the average of the unit level causal effects in a sample. This average causal effect or average treatment effect (ATE) is a powerful concept because it is one solution to the problem of not observing all relevant counterfactuals. Yet, it is not the only productive engagement with this problem. In fact, there are many different types of quantities of causal interest. The goal of this guide is to help you choose estimands (a parameter of interest) and estimators (procedures for calculating estimates of those parameters) that are appropriate and meaningful for your data.

[^1]: See Holland (1986) and Angrist and Pischke  Angrist, Joshua, and Jörn-Steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.

1 Average Treatment Effects
==
We begin by reviewing how, with randomization, a simple difference-of-means provides an unbiased estimate of the ATE. We take extra time to introduce some common statistical concepts and notation used throughout this guide.

First we define a treatment effect for an individual observation (a person, household, city, etc.) as the difference between that unit’s behavior under treatment $(Y_{i}(1))$ and control $(Y_{i}(0))$:

$$τ_{i}=Y_{i}(1)−Y_{i}(0)$$

Since we can only observe either $Y_{i}(1)$ or $Y_{i}(0)$ the individual treatment effect is unknowable. Now let $D_{i}$ be an indicator for whether we observe an observation under treatment or control. If treatment is randomly assigned, $D_{i}$ is independent, not only of potential outcomes but also of any covariates (observed and unobserved) that might predict also those outcomes $((Y_{i}(1),Y_{i}(0),X_{i}⊥⊥D_{i}))$.[^2]

[^2]: See Holland and Angrist & Pischke again for more formal discussion of independence and the assumptions necessary to estimate causal effects.

Suppose our design involves m units under treatment and N−m under control. Suppose we were to repeatedly reassign treatment at random many times and each time calculate the difference of means between treated and control groups and then to record this value in a list. The average of the values in that list will be the same as the difference of the means of the true potential outcomes had we observed the full schedule of potential outcomes for all observations. 2 Another way to say this characteristic of the average treatment effect and the estimator of it, is to say that the difference of observed means is an unbiased estimator of the average causal treatment effect.

ATE≡(1/N)∑Ni=1τi=∑N1Yi(1)N−∑N1Yi(0)N

And we often estimate the ATE using the observed difference in means:3

ATEˆ=∑m1ZiYim−∑Nm+1(1−Zi)YiN−m

Statistical inference about the estimated ATE requires that we know how it will vary across randomizations. It turns out that we can write the variance of the ATE across randomizations as follows:

V(ATE)=NN−1[V(Yi(1))m+V(Yi(0))N−m]−1N−1[V(Yi(1))+V(Yi(0))−2∗Cov(Yi(1),Yi(0))]

and estimate this quantity from the sample estimates of the variance in each group.4

A linear model regressing the observed outcome Yi on a treatment indicator Di provides a convenient estimator of the ATE (and with some additional adjustments, the variance of the ATE):

Yi=Yi(0)∗(1−Di)+Yi(1)∗Di=β0+β1Di+u

since we can rearrange terms so that β0 estimates the average among control observations (Yi(0)∣Di=0) and β1 estimates the differences of means (Yi(1)∣Di=1)–(Yi(1)∣Di=0). In the code below, we create a sample of 1,000 observations and randomly assign a treatment Di with a constant unit effect to half of the units. We estimate the ATE using ordinary least squares (OLS) regression to calculate the observed mean difference. Calculating the means in each group and taking their difference would also produce an unbiased estimate of the ATE. Note that the estimated ATE from OLS is unbiased, but the errors in this linear model are assumed to be independent and identically distributed. When our treatment effects both the average value of the outcome and the distribution of responses, this assumption no longer holds and we need to adjust the standard errors from OLS using a Huber-White sandwich estimator to obtain the correct estimates (based on the variance of the ATE) for statistical inference 5. Finally, we also demonstrate the unbiasedness of these estimators through simulation.




```{r, echo = F, results = 'asis'}
library(xtable)
x <- sample(c(0, 1), 100, replace = T)
y <- sample(c(0, 1), 100, replace = T)
print(xtable(table(x, y)))
```

