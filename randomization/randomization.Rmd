
---
output: 
  html_document:
    toc: true
    theme: journal
---

<!-- title: "10 Things You Need to Know About Randomization" -->
<!-- author: "Methods Guide Author: Lindsay Dolan" -->

Resumen
==
Esta guía le ayudará a diseñar y ejecutar diferentes tipos de asiganción aleatoria en sus experimentos. Nos centramos en las grandes ideas y proporcionamos ejemplos y herramientas que puede utilizar en R. Para saber por qué aleatorizar, consulte [esta guía de métodos](http://egap.org/resource/10-strategies-for-figuring-out- si-x-causó-y).

1 Unas formas son mejores que otras
==
Hay muchas formas de aleatorizar. La más simple es lanzar una moneda para determinar si un sujeto recibe un tratamiento o no. Esto asegura que cada sujeto tenga una probabilidad de 0.5 de recibir el tratamiento y una probabilidad de 0.5 de no recibirlo. Hecho de esta manera, si un sujeto recibe el tratamiento no afecta de ninguna manera si el siguiente sujeto recibe el tratamiento, cada sujeto tiene la misma probabilidad de recibir el tratamiento y el tratamiento no estará correlacionado con factores que puedan generar una asociación aparente, al menos en expectativa.


Este no es un procedimiento erróneo, pero tiene sus carencias. Primero, al usar este método no puede saber de antemano cuántas unidades estarán en tratamiento y cuántas en control. Si para usted es importante tener esta información de antemano, deberá emplear alguna forma de muestreo en la que cada elemento selccionado no sea estadísticamente independientes de los otros (como sacar fichas con nombres de un sombrero). En segundo lugar, es posible que desee ejercer el control sobre la proporción exacta de unidades asignadas al tratamiento y control, lo que es difícil de conseguir con una moneda. En tercer lugar, es posible que desee poder replicar su aleatorización para demostrar que no hubo nada raro con ella. Eso no se puede hacer tan fácil con monedas y sombreros. Finalmente, como mostramos a continuación, hay todo tipo de formas de hacer la aleatorización para mejorar el poder y asegurar el balance de varias formas que son muy difíciles de lograr usando monedas y sombreros.

Sin embargo, afortunadamente, la aleatorización replicable y flexible es muy fácil de hacer con software disponible gratuitamente. El siguiente código de R se puede utilizar, por ejemplo, para generar una asignación aleatoria, especificando el número de unidades a tratar. Aquí, N (100) es el número de unidades que tiene y m (34) es el número que desea tratar. La "semilla" permite replicar la misma simulación cada vez que ejecuta el código (o puede cambiar la semilla por iteración diferente de la simulación). [^1] [^2]



[^1]: Los generadores de números aleatorios son en realidad pseudoaleatorios porque generan un vector de números aleatorios basado en un pequeño conjunto de valores iniciales, conocido como  estado de semilla. Los generadores de números aleatorios funcionan de esta manera para mejorar la velocidad computacional. Sin embargo, la serie de números aleatorios generada es tan aleatoria como es necesario para los propósitos de la asignación aleatoria porque no tiene ninguna relación con los resultados potenciales de sus sujetos.

[^ 2]: Todos los fragmentos de código fueron actualizados por Alex Coppock el 25 de noviembre de 2020.



```{r, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(randomizr)
set.seed(343)
complete_ra(100, 34)
```

2  Aleatorización en bloques: puede asegurarse de antemano que los grupos de tratamiento y control estén balanceados
==
Cuando aleatorizaramos podemos asegurarnos de que los grupos de tratamiento y de control estén balanceados con respecto a  factores particularesque sean de nuestro interés. Clar están, que no es posible especificar qué unidades particulares se seleccionan para cada grupo y mantener la asignación aleatoria.

Esto significa que es posible especificar, por ejemplo, que sus grupos de tratamiento y control contienen proporciones iguales de hombres a mujeres. En otras palabras, esto evita cualquier aleatorización que pueda producir un grupo de tratamiento claramente masculino y un grupo de control claramente femenino, o viceversa.

¿Por qué es esto deseable? El que queramos grupos balanceado no tiene que ver con una posible estimación sesgada del efecto promedio del tratamiento, sino porque la estimación podría ser realmente ruidosa. Supongamos que una asignación aleatoria generara un grupo de tratamiento con muchos hombres y un grupo de control muchas mujeres. En dado caso, observaríamos una correlación entre género y tratamiento. Si tuviéramos que estimar un efecto del tratamiento, ese efecto del tratamiento aún sería insesgado  porque el género no tiene ninguna influencia sobre asignación del tratamiento. Sin embargo, sería más difícil rechazar la hipótesis nula de que es el género y no nuestro tratamiento el que produce el efecto. En resumen, el desbalance produce una estimación ruidosa, lo que nos dificulta tener confianza en nuestras estimaciones.

La aleatorización en bloques (a veces llamada estratificada) nos ayuda a manipular nuestro experimento para que nuestros grupos de tratamiento y control estén balanceados en dimensiones importantes, pero aún así se asignen al azar. Esencialmente, este tipo de diseño de aleatorización construye múltiples mini-experimentos: por ejemplo, podría tomar mujeres y asignar al azar la mitad al tratamiento y la mitad al control, y luego asignaría la mitad de los hombres al tratamiento y la mitad al control. Esto garantiza un balance con respecto al género cuando se combinan los grupos de tratamiento y de control.


El [paquete blockTools ](https://cran.r-project.org/web/packages/blockTools/index.html) es util para hacer aleatorización en bloques. Comencemos por generar datos artificiales para 60 sujetos, 36 de los cuales son hombres y 24 mujeres.

Supongamos que queremos hacer asignación en bloques en función del género Basados en nuestros datos, blockTools generará los bloques más pequeños posibles, cada uno con dos unidades del mismo género: una asignada al tratamiento y la otra al control.

```{r, results='hide', error=FALSE, message=FALSE, warning=FALSE}
rm(list = ls())

library(blockTools)
library(dplyr)
library(randomizr)

dat <-
  tibble(
    id = seq(1:60),
    female = c(rep(0, 36), rep(1, 24)),
    age = sample(18:65, size = 60, replace = TRUE)
  )

# Bloque de una covariable

dat <-
  dat %>%
  mutate(Z_block_1 = block_ra(female))

with(dat, table(female, Z_block_1))

# Cuartetos emparajedos
out <- block(dat, n.tr = 4, id.vars = "id", 
             block.vars = c("female", "age"))

dat <-
  dat %>%
  mutate(
    block_id = createBlockIDs(out, dat, id.var = "id"),
    Z_block_2 = block_ra(block_id))

with(dat, table(Z_block_2, block_id))
```


Puede verificar la media de la variable en la que bloqueó el tratamiento y el control para ver que los grupos de tratamiento y control están, de hecho, perfectamente balanceados en función del género.

 

3 diseños factoriales: puede aleatorizar múltiples tratamientos al mismo tiempo sin perder poder
==
Supongamos que hay varios componentes de un tratamiento sobre los cuales quiere hacer pruebas. Por ejemplo, es posible que desee evaluar el impacto de un programa de microfinanzas. Dos tratamientos específicos podrían ser prestar dinero a las mujeres y brindarles capacitación. Un diseño factorial analiza todas las combinaciones posibles de estos tratamientos: (1) Préstamos, (2) Capacitación, (3) Préstamos + Capacitación y (4) Control. Luego, los sujetos se asignan al azar a una de estas cuatro condiciones.


![](https://raw.githubusercontent.com/egap/methods-guides/master/randomization/factorial-table.png)

Los diseños factoriales son especialmente útiles para evaluar intervenciones que incluyen un paquete de tratamientos. Así como en el ejemplo anterior, muchas intervenciones de desarrollo vienen con varios componentes (brazos) y, a veces, es difícil saber qué componente están produciendo el efecto observado. Un diseño factorial separa estos diferentes tratamientos y también nos permite ver la interacción entre ellos.

El siguiente código enseña cómo aleatorizar utilizando un diseño factorial



```{r, results='hide'}
dat <-
  tibble(
    Z_loan = complete_ra(80, 40),
    Z_training = block_ra(blocks = Z_loan)
  )

with(dat, table(Z_loan, Z_training))
```

4 You can randomize whole clusters together (but the bigger your clusters, the weaker your power!)
==
Sometimes it is impossible to randomize at the level of the individual. For example, a radio appeal to get individuals to a polling station must inherently be broadcast to a whole media market; it is impossible to broadcast just to some individuals but not others. Whether it is by necessity or by choice, sometimes you will randomize clusters instead of individuals.

The disadvantage of cluster randomization is that it reduces your power, since the number of randomly assigned units now reflects the number of clusters and not simply your total number of subjects. If you had two randomly assigned clusters of 1,000 individuals each, the functional number of units might be closer to 2, not 2,000. For this reason, it is preferable to make clusters as small as possible.

Similarly, it is also desirable to have heterogeneity within your clusters so that they are as representative as possible of your broader population. If the individuals within individual clusters are very similar to each other, they may have similar potential outcomes, and that group with similar potential outcomes is going to be assigned to treatment or control as a group. Overall, this will increase your variance if that cluster had particularly high or low potential outcomes because it increases the overall correlation between potential outcomes and treatment assignment. In brief, if your clusters are more representative of the broader population, your estimates of the average treatment effect will be more precise.

A frequently asked question is how cluster randomization differs from block randomization. Block randomization is conducted in order to achieve balance based on pre-treatment covariates. For example, an education intervention might block randomize on the previous year’s test scores in order to track the progress of both low- and high-performing students. Cluster randomization is when multiple units are treated as a group–they all receive treatment or control status together. For example, the same education intervention might randomize at the level of the classroom, so the classrooms constitute the clusters. It is possible to block and cluster randomize simultaneously. In our example, you might calculate the average test score for each classroom and block randomize based on the classroom’s average score.

The following graphic demonstrates what your data might look like in the cases of block, cluster, and block + cluster randomization, relative to a simple case of randomization with no blocking or clustering. In both cases where clustering occurs, you can tell that treatment assignment (depicted by color) appears in small groups. In both cases where blocking occurs, there is an even distribution of colors in the four quadrants of the plot, the blocks of this random assignment.

![](https://raw.githubusercontent.com/egap/methods-guides/master/randomization/randomizations1.png)
<center>_Illustration of the patterns of treatment and control units you might see under different types of blocked and clustered designs._</center>

5 You can randomize in a way that makes it easier to see if there are spillovers
==
When designing your experiment, think critically about whether “spillovers” pose a threat to your ability to identify the causal effect of your treatment. Spillovers arise if one units outcome is affected by the treatment status of another unit. This can be tricky if units have the ability to interact with each other: one member of a village may learn of another villager’s receipt of a cash grant and may change their behavior accordingly.

One way to make spillovers more evident is to use double randomization. You would first randomly assign some clusters to treatment and others to control, and within clusters, you would assign some individuals to treatment and others to control. Comparing control individuals in your treatment cluster to individuals in your control cluster will enable you to assess the role of spillovers in your experiment.

6 Different units can be assigned to treatment with different probabilities
==
Sometimes people think that “random” means that two events are equally likely, but in fact, random assignment is “random” so long as the probability of assignment to treatment is strictly between 0 and 1. If a subject has a 0 or a 100 percent chance of being assigned to treatment, that subject should be excluded from your experimental analysis because there is no randomization occurring. However, all subjects with a probability of assignment to treatment strictly between 0 and 1 may be included, even if their probabilities differ, so long as their probabilities are known.

Why might you want to assign different probabilities of assignment to treatment? Suppose you are working with an implementing partner to randomize the allocation of election observers in order to measure the effect on electoral fraud. Your implementing partner can afford to send only a few election observers to a rural part of the country. You could address this constraint by blocking on geographic area and assigning a higher probability of assignment to treatment to more proximate villages to which it is less costly to travel. So long as the probability of assignment to treatment for more accessible villages is less than 1, the probability of assignment to treatment for less accessible villages is greater than zero, and these probabilities are known, it is possible to estimate the effect of the treatment.

When subjects have differing probabilities of assignment to treatment, however, you can no longer simply merge all subjects in the analysis of your data. If you do, then treatment assignment will be correlated with background characteristics on which you blocked. There are two ways of handling this.

The first way is to estimate the average treatment effect block by block and then to average the treatment effects, each weighted by the size of the block relative to the entire sample.

The second way is inverse probability weighting (IPW). In IPW, weights are defined as the 1/p for treated units and 1/(1-p) for control units, where p refers to the probability of assignment to treatment. This method allows you to run a weighted regression of Y on treatment assignment.

```{r, results='hide'}
N <- 100000
dat <- tibble(Y0 = 1:N,
              Y1 = Y0 + 10000)

dat <-
  dat %>%
  mutate(
    p = seq(0.25, 0.75, length.out = N),
    Z = simple_ra(N, prob_unit = p),
    Y = Z * Y1 + (1 - Z) * Y0)
  
dat %>%
  summarise(
    naive_estimate = mean(Y[Z == 1]) - mean(Y[Z == 0]),
    ipw_estimate = weighted.mean(Y[Z == 1], 1 / p[Z == 1]) -
      weighted.mean(Y[Z == 0], 1 / (1 - p[Z == 0]))
  )
```

7 Restricted randomization: If you don’t like what you get you can start over
==
It might seem inconsistent with the whole idea of randomization that you throw out  a random assignment because you don’t like what is chosen. But sometimes this makes sense.  Sometimes you might want to make sure that randomization does not produce particular types of pattern (for example, too many people who know each other all being in treatment).  But the patterns you care about might be too hard to set up in advance. What you can then do is take a random draw and then see whether the draw meets the criteria you care about or not, if it doesn’t, then draw again.  Be warned, though, that if you do this, you create a couple of complications: (1)  each unit will not necessarily be assigned with the same probability, (2) units may not be independently assigned to treatment.  You need to take into account both of these facts in your analysis, for example, by generating inverse probability weights as we did in point 6 but using the same restricted randomization code to figure out how likely it is that each subject is assigned to treatment under these restrictions. Next, you use the distribution of possible treatment assignments to implement randomization inference. These analyses are complex so proceed with caution.

8 Write randomization code that lets you simulate many possible randomizations
==
A benefit of using R code to randomize is that you can perform thousands of possible randomizations in seconds. Why is this beneficial?

1. It can be useful as a way to check whether your randomization code worked. For example, if one or more subjects in your experiment never received treatment over 10,000 possible random assignments, then you would suspect a flaw in your randomization code.
2. You can use re-randomization to calculate the exact probability of assignment to treatment for each individual in your experiment. This is especially helpful if your randomization code is more complex. Perhaps you employ both block and cluster randomization, resulting in greatly different probabilities of assignment to treatment for individuals in a large experiment. These probabilities would be difficult to calculate by hand, but an easy solution is to run your original randomization code many times and generate a variable representing each individual’s proportion of times they were assigned to treatment: this represents his or her individual probability of assignment to treatment. This variable can then be used in a weighted regression when calculating the average treatment effect.
3. Simulating possible randomizations is a design-based approach to calculating statistical significance. This approach, called randomization inference, generates an exact p-value by calculating possible average treatment effects that would be observed under hypothetical random assignments if in fact the treatment had no effect. The p-value is then the proportion of the estimated treatment effects that is at least as large in magnitude as the one that your experiment observed. This approach is preferable to standard calculations of statistical significance when the distribution of your data is not normal because randomization inference avoids making distributional assumptions and instead uses distribution of data observed in your experiment. For more information on randomization inference, including sample code, visit the [10 Things to Know About Randomization Inference](https://egap.org/resource/10-things-to-know-about-randomization-inference/) Methods Guide.

9 You can do randomization as you go along
==
In many experiments, you may not know the entirety of your sample at the beginning of the experiment; some subjects may join over time. This presents a complication when we want to use a simple blocking algorithm because the addition of subjects to our pool may change the composition of our blocks and therefore their probabilities of assignment to treatment.

To maintain the ability to block and therefore the ability to assert control over the balance between treatment and control groups, you can use covariates to calculate a new subject’s similarity to other previously assigned subjects and assign the new subject to the treatment condition with fewer similar units.[^3] [^4]

[^3]: For more, see Moore, Ryan T., and Sally A. Moore. “Blocking for sequential political experiments.” Political Analysis 21.4 (2013): 507-523.

[^4]: For a more detalied walkthrough on the randomization procedures available in the R package randomizr, see: https://declaredesign.org/r/randomizr/articles/randomizr_vignette.html

10 Randomization can sometimes be an ethical way of assigning a treatment, but sometimes it isn’t
==
Randomization is the key ingredient for isolating the causal effect of a treatment from a research design perspective, but it is also important to consider the ethical implications of randomization as well. When we think about the long-term effects of an experiment, randomization enables us to test which programs are most effective so that resources can be directed to programs that make the most difference in the lives of future populations. In the short term, randomizing access to a program (as opposed to distributing based on arbitrary characteristics) can be a particularly ethical way of distributing scarce goods that cannot be extended to everyone.

However, sometimes, it is the neediest populations that need to be served by an intervention in an experiment. A randomized design that treats equal numbers of low-income and high-income participants with loans is letting resources flow to less rather than more needy individuals. If we believe there are beneficial effects of the loan, then this raises concerns about the ethics of allocating resources away from the neediest.[^5] One would need a strong case for social benefits of the research and would also seek designs that provide benefits ultimately to control groups.

[^5]: But if we are certain about the loan’s effects, then it’s also unclear why we are running an experiment to test it. In medical research, randomized controlled trials often stop if it becomes clear early on that a drug is undoubtedly curing life-threatening diseases, and therefore withholding it from control subjects is dangerous. (Similarly, a trial would also stop if it were clear early on that a drug is undoubtedly causing negative and harmful effects.)

A wait list randomization design is one way of treating an entire subject pool while enabling the researcher to test the effectiveness of the treatment experimentally. In this design, the program could roll out the intervention in phases and randomly assign the units to the phase in which they will be treated. For example, if a program wanted to treat 90 villages in total, it could treat 30 villages each year, and measure outcomes at the end of each year. If you wanted to compare outcomes in treatment and control villages, you would compare the 30 treated villages to the 60 yet-untreated villages at the end of the first year. At the end of the second year, you could compare the 30 villages that were treated in the previous year to the 30 villages that are yet-untreated. Essentially, this creates two experiments, identical but for the year’s time that separates them. In the table below, you can see that in the first year, we could compare the dark blue treatment group to the two light blue control groups. In the second year, we could compare the dark red treatment group to the light red treatment group, but we would want to avoid pooling the two treatment groups because one has been treated for longer than the other. You can see that after the third year, no more comparisons may be made because all units have been treated.

![](https://raw.githubusercontent.com/egap/methods-guides/master/randomization/wait-list-table.png)

The only requirement is that a subject’s assignment to treatment in a particular phase is randomly assigned and unrelated to their potential outcomes of interest. A design in which more eager participants received treatment earlier would violate this assumption and would not yield an unbiased estimate of the treatment effect, as unobserved factors that predispose them to seeking out treatment may be influencing their schedule of potential outcomes. The wait list design is an example of a creative randomization design that could address ethical concerns about limiting the distribution of a valuable treatment.

Ethics are often highly intertwined with randomized designs, especially in social science and medical research. As a researcher, you should carefully consider the possible implications of randomizing any given treatment. You will also need to solicit approval for your research design from your research institution’s Institutional Review Board (IRB).