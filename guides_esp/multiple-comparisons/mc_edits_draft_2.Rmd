---
title: 'Multiple Comparisons: Index Methods'
author: "Tara Slough"
date: "November 28, 2015"
output: html_document
---

Additional Edits:

Under section 1, add \# 4 below:

1. **Multiple treatment arms.** When an experiment has $n$ treatment arms, there are $n(n-1)/2$ possible comparisons.
2. **Heterogeneous treatment effects.** Often, we are interested in whether the treatment has different impacts on different subgroups.  For example, a treatment might be more effective for women than for men.
3. **Multiple estimators.** Often, experimenters will apply multiple estimators to the same dataset: for example, difference-in-means and covariate adjustment.
4. **Multiple outcomes.** Researchers often assess the effects of an intervention on multiple distinct outcomes or multiple operationalizations of the outcome variable.

Creating an index is a way to get a single comparison out of many.
==================================================================

Suppose a researcher measures $k>1$ dependent variables. Indexing allows the researcher to reduce these $k$ outcomes into a single measure (or several thematically-grouped measures). These indexing methods effectively condense the number of dependent variables that investigators test in order to address the multiple comparisons problem. There are a number of ancillary benefits of these indexing methods:

- Unlike the other methods of addressing the multiple comparisons problem, the indexing approach may reward researchers for *increasing* the number of dependent variables. Imagine that a researcher collects $k=50$ outcome variables and that the treatment does not cause significant differences for any of them, but all the point estimates are in the same direction. If we were to apply a multiple comparisons correction to our 50 tests, our results would get even murkier. However, if we combine all 50 dependent variables into a single index, the resulting dependent variable may in fact exhibit significant differences. 
- In the presence of limited amounts of attrition across outcomes, these methods *may* provide some leverage for dealing with missingness on some dependent variables (but not for units for which outcome variables are entirely unobserved).

There are two principle indexing methods in the literature:

Mean Effects Index
------------------

[Kling, Liebman, and Katz (2004)]((http://www.nber.org/mtopublic/483.pdf)) employ a mean effects index, constructed as follows:

1. If necessary, reorient some outcomes so that beneficial effects are consistently scored higher across all outcomes. 
2. Calculate a $z$-score, $\tilde{y}_{ik}$ by subtracting off the *control* group mean and dividing by the *control* group standard deviation, as follows, where $i$ indexes individuals and $k$ indexes outcomes: 


$$\tilde{y}_{ik}= \frac{y_{ik}- \bar{y}_k^{Z=0}}{\sigma_{k}^{y,Z=0}}$$

3. Sum the $z$-scores, $\sum_{i=1}^K \tilde{y}_{ik}$ (optionally) divide by $K$ to generate the index.

4. Optional: It may be desirable to normalize the final index by the control group mean and standard deviation.

In the presence of missing outcomes, one of two approaches could be employed:

1. **Imputation**: Kling, Liebman, and Katz advocate a imputation approach for missing values on individual outcomes. Specifically, prior to constructing the index, compute the mean of each outcome variable for each experimental group, $\bar{y}_{ik}^{Z=1}$ and $\bar{y}_{ik}^{Z=0}$ using the above notation. Then, impute the mean corresponding to a unit's assignment status (treatment or control) prior to constructing the index.
2. **"Greedy" Indexing**: Instead of imputing values of missing outcome variables ex-ante as in method 1, calculate the $z$-scores as above. Where there are missing values for the "raw" outcome variables, there will be missing $z$-scores. For each unit, sum the non-missing $z$-scores and then divide by the number of non-missing outcomes. Hence, instead of dividing $\sum_{i=1}^K \tilde{y}_{ik}$ by $K$ as above, we calculate $K_{i}$, the number of non-missing outcomes, for each unit.

Inverse Covariance Weighted Index
---------------------------------

[Anderson (2008)](https://are.berkeley.edu/~mlanderson/pdf/Anderson%202008a.pdf) provides a similar approach that constructs an index that employs inverse covariance weighting. This weighting scheme improves efficiency relative to the mean effects index above by affording less weight to highly correlated outcomes. The Anderson index can be constructed through the following procedure:

1. If necessary, reorient some outcomes so that beneficial effects are consistently scored higher across all outcomes. 
2. Calculate a $z$-score, $\tilde{y}_{ik}$ by subtracting off the *control* group mean and dividing by the *control* group standard deviation, as follows, where $i$ indexes individuals and $k$ indexes outcomes: 


$$\tilde{y}_{ik}= \frac{y_{ik}- \bar{y}_k^{Z=0}}{\sigma_{k}^{y,Z=0}}$$

3. Construct and invert the (variance)-covariance matrix of the resultant matrix of $z$-scores calculated in step 2. Call this $k \times k$ inverted (variance)-covariance matrix $\hat{\boldsymbol{\Sigma}}^{-1}$. 

4. The weighted indexed outcome, $\bar{s}_i$ can be estimated via the following procedure, where $\textbf{1}$ is a $k \times 1$ vector of ones and $\textbf{y}_{ik}$ is the $n \times k$ matrix of $z$-scores calculated in step 2.

$$\bar{s}_i = (\textbf{1}^T \hat{\boldsymbol{\Sigma}}^{-1} \textbf{1})^{-1}(\textbf{1}^T \hat{\boldsymbol{\Sigma}}^{-1} \textbf{y}_{ik})$$

5. Optional: As above, it may be desirable to normalize the final index by the control group mean and standard deviation.

As with the mean effects index, this varible $\bar{s}_i$ the serves as the dependent variable in your analysis. One potential drawback to the inverse covariance weighting index is that there is no guarantee that elements in the inverted covariance matrix ($\boldsymbol{\Sigma}^{-1}$) are positive. As such, it is possible to generate negative weights using this indexing method. Given that outcomes are oriented in the same direction, a negative weight effectively reverses the direction of the effect on negatively-weighted outcomes in the construction of the index.  

The following functions implement both the mean effects and inverse covariance weighted index methods and evaluate both functions on a DGP with 50 outcome measures:

```{r, warning = F, message = F}
stopifnot(require(mvtnorm))
stopifnot(require(dplyr))
stopifnot(require(randomizr))
stopifnot(require(ggplot2))

set.seed(1234)

calculate_mean_effects_index <- function(Z, outcome_mat, to_reorient, reorient = FALSE, greedy = TRUE,
                                impute = FALSE){
  if(length(Z) != nrow(outcome_mat)) stop("Error: Treatment assignment, outcome matrix require same n!")
  if(impute == TRUE){
    R <- 1 * is.na(outcome_mat)
    means_for_imputation <- rbind(apply(outcome_mat[Z==0,], MAR = 2, FUN = mean, na.rm = T),
                                  apply(outcome_mat[Z==1,], MAR = 2, FUN = mean, na.rm = T))
    to_impute <- R * means_for_imputation[Z+1,]
    outcome_mat[is.na(outcome_mat)] <- 0
    outcome_mat <- outcome_mat + to_impute
  }
  c_mean <- apply(X = outcome_mat[Z==0,], MARGIN = 2, FUN = mean, na.rm = T)
  c_sd <- apply(X = outcome_mat[Z==0,], MARGIN = 2, FUN = sd, na.rm = T)
  z_score <- t(t(sweep(outcome_mat, 2, c_mean))/ c_sd)
  index_numerator <- rowSums(z_score)
  if(greedy == TRUE){
    n_outcomes <- rowSums(!is.na(z_score))
  }
  else if(greedy == FALSE){
    n_outcomes <- ncol(outcome_mat)
  }
  index <- index_numerator/n_outcomes
  index <-  (index - mean(index[Z==0], na.rm =T))/sd(index[Z==0], na.rm =T)
  return(index)
}

calculate_inverse_covariance_weighted_index <- function(Z, outcome_mat, to_reorient, reorient = FALSE){
  if(length(Z) != nrow(outcome_mat)) stop("Error: Treatment assignment, outcome matrix require same n!")
  if(reorient == TRUE){
    outcome_mat[, c(to_reorient)] <- -outcome_mat[, c(to_reorient)] 
  }
  c_mean <- apply(X = outcome_mat[Z==0,], MARGIN = 2, FUN = mean, na.rm = T)
  c_sd <- apply(X = outcome_mat[Z==0,], MARGIN = 2, FUN = sd, na.rm = T)
  z_score <- t(t(sweep(outcome_mat, 2, c_mean))/ c_sd)
  Sigma_hat <- solve(cov(z_score, y = z_score, use = "complete.obs"))
  one_vec <- as.vector(rep(1, ncol(outcome_mat)))
  if(sum(is.na(outcome_mat))>0){
    z_score[is.na(z_score)] <- 0
  }
  w_ij <- t(solve(t(one_vec) %*% Sigma_hat %*% one_vec) %*% (t(one_vec) %*% Sigma_hat))
  if(sum(w_ij < 0) > 0){warning('Warning, at least one weight is negative!')}
  s_ij <- t(solve(t(one_vec) %*% Sigma_hat %*% one_vec) %*% (t(one_vec) %*% Sigma_hat %*% t(z_score)))
  index <- (s_ij - mean(s_ij[Z==0], na.rm = T))/sd(s_ij[Z==0], na.rm = T)
  return(s_ij)
}
```

We can see how these indices perform in a setting with $k = 5$ outcome variables.

<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>

<div class="hidecode" onclick="doclick(this);">[Click to show code]</div>
```{r, message = F, warning = F}
# A DGP with K outcome variables
# Untreated potential outcomes drawn from multivariate normal distribution
K <- 5
r <- runif(n = K, min = -.9, max = .9)
sigma <- outer(r, r, FUN = "*")
diag(sigma) <- 1
mat <- rmvnorm(n = 200, mean = rep(0, K), sigma = sigma)

# Treatment assignment
Z <- complete_ra(200)

# Created observed potential outcomes
# Assume that ATEs are all oriented in the same direction for the time being
ATEs <- rnorm(K, mean = .25, sd = 1)

for(i in 1:K){
  mat[,i] <- mat[,i] + rnorm(n = 200, mean = Z * ATEs[i], sd = 1)
}

mean_effects_index <- calculate_mean_effects_index(Z = Z, outcome_mat = mat, reorient = F)
inv_cov_weighted_index <- calculate_inverse_covariance_weighted_index(Z = Z, outcome_mat = mat,reorient = F)
```

First, we can examine the properties of the indices alongside our five outcome variables by looking at the covariance matrix.

<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>

<div class="hidecode" onclick="doclick(this);">[Click to show code]</div>
```{r}
knitr::kable(cov(data.frame(mat, mean_effects_index, inv_cov_weighted_index)), digits = 3)
```

We can also plot the two indices to show their similarities (or differences). Note that with the final normalization included in the functions above, both indices are on the same scale.

<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>

<div class="hidecode" onclick="doclick(this);">[Click to show code]</div>
```{r}
data.frame(Z, mean_effects_index, inv_cov_weighted_index) %>%
  mutate(Group = ifelse(Z==1, "Treatment", "Control")) %>%
  ggplot(aes(x = mean_effects_index, y = inv_cov_weighted_index, colour = Group)) + 
  geom_point() + theme_bw() + xlab("Mean Effects Index") + ylab("Inverse Covariance Weighted Index")
```

We can estimate treatment effect on the indexed variable using OLS or a difference-in-means. Note that given the normalization of both indices, the coefficient estimates are on the same scale and thus directly comparable.

<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>

<div class="hidecode" onclick="doclick(this);">[Click to show code]</div>
```{r}
table <- rbind(summary(lm(mean_effects_index ~ Z))$coef["Z", c (1, 2, 4)], 
        summary(lm(inv_cov_weighted_index ~ Z))$coef["Z", c(1, 2, 4)])
rownames(table) <- c("Mean Effects Index", "Inverse Covariance Weighted Index")
colnames(table) <- c("Estimate", "Std. Error", "p-value")
knitr::kable(table, digits = 3)
```